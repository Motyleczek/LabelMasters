{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obliczanie miar dla wyników detekcji systemu\n",
    "\n",
    "W tym notebooku zarówno obliczane były finalne wyniki WER, CER oraz MER, ale i tutaj zapisane były przykładowe detekcje do pokazania w analizie wyników w pracy magisterskiej. \n",
    "\n",
    "Wyniki uzyskane z dwóch ostatnich komórek tego notebooka zostały zaprezentowane w analizie wyników pracy magisterskiej. \n",
    "\n",
    "Część tego notebooka (zaznaczona odpowiednio) była przeliczona na środowisku Google Colabolatory ze względu na inną architekturę mojej lokalnej maszyny w porównaniu do środowiska w którym uczony był model. Niemniej jednak finalne obliczenia na zapisanych detekcjach zostały przeprowadzone lokalnie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importy oraz przygotowanie pomocnych funkcji/narzędzi\n",
    "\n",
    "import jiwer\n",
    "import pytesseract\n",
    "import cv2\n",
    "import os \n",
    "import numpy as np\n",
    "import pickle\n",
    "import io\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# funkcje do  preprocessingu obrazów przed detekcjami tesseract\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# transformacje potrzebne do poprawnego obliczania WER/MER/CER \n",
    "transforms = jiwer.Compose(\n",
    "    [\n",
    "        jiwer.RemoveEmptyStrings(),\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.Strip(),\n",
    "        jiwer.RemovePunctuation(),\n",
    "        jiwer.ReduceToListOfListOfWords(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Przeliczone na collabolatory:** komórka bezpośrednio pod spodem została przeliczona w tym samym środowisku co trenowanie modelu. Po obliczeniach wyniki zostały zapisane z pomocą biblioteki `pickle` a następnie przeliczone lokalnie (kolejne komórki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# całość poniej była puszczona na colabie, ze względu na błędy modelu kiedy puszczałem go lokalnie\n",
    "# tak pozyskałem wyniki (results) dla zbiorów treningowego, validacyjnego oraz testowego\n",
    "# te wyniki uzywam ponizej razem z biblioteką jitter do obliczenia wynikow WER\n",
    "\n",
    "######################\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# print(\"loading model\")\n",
    "# model = YOLO(\"ran_on_colab/weights/best_best.pt\")\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# path_to_train_im = \"ran_on_colab/images/test/\"\n",
    "# path_to_train_info_excel = \"data/generated_labels/first_gen_2024-06-24.xlsx\"\n",
    "\n",
    "# files_np = np.array(os.listdir(path_to_train_im))\n",
    "# file_paths = np.char.add(path_to_train_im, files_np)\n",
    "\n",
    "# file_paths_short = file_paths[:20]\n",
    "\n",
    "# results = model(source=file_paths_short.tolist())\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładowanie plików pickle zwróconych przez bibliotekę torch musi zostać przeprowadzone w specyficzny sposób ze wzgledu na inne architektury sprzętu na którym prowadzona była nauka modelu (GPU) a na którym liczone są miary (CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ze wzgledu na roznice maszyn potrzeba otworzyć w specjlany sposob:\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "with open(\"ran_on_colab/results_saved/train/train_results.pkl\", \"rb\") as file:\n",
    "    loaded_train_results = CPU_Unpickler(file).load()\n",
    "\n",
    "with open(\"ran_on_colab/results_saved/test/test_results.pkl\", \"rb\") as file:\n",
    "    loaded_test_results = CPU_Unpickler(file).load()\n",
    "    \n",
    "with open(\"ran_on_colab/results_saved/val/val_results.pkl\", \"rb\") as file:\n",
    "    loaded_val_results = CPU_Unpickler(file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label_tag</th>\n",
       "      <th>label_type</th>\n",
       "      <th>uwagi</th>\n",
       "      <th>odbiorca</th>\n",
       "      <th>nadawca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhl_1</td>\n",
       "      <td>Proszę zadzwonić domofonem.</td>\n",
       "      <td>Magdalena Kozak ul. Michałowska 113 03-767 W...</td>\n",
       "      <td>Mateusz Stępień ul. Nawigacyjna 19 60-480 Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inpost_3</td>\n",
       "      <td>Upewnić się, że ktoś odbierze</td>\n",
       "      <td>MORSKI KWIAT   ul. Wałuszewska 55 03-005 Warsz...</td>\n",
       "      <td>SŁONECZNA POLANA   ul. Obrzańska 86 60-114 Poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>inpost_3</td>\n",
       "      <td>Zadzwonić na numer kontaktowy</td>\n",
       "      <td>Gabriela Pawlik ul. Mickiewicza Adama 113 81...</td>\n",
       "      <td>Maria Nowak ul. Generała Fiszera Józefa 20 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>dhl_1</td>\n",
       "      <td>Proszę o delikatne obchodzeni</td>\n",
       "      <td>Mariusz Piekarski ul. Mała 144 15-317 Białys...</td>\n",
       "      <td>Krzysztof Kwiatkowski ul. Brzozowa 125 43-60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>pocztex_1</td>\n",
       "      <td>Proszę dostarczyć na tylną fu</td>\n",
       "      <td>Paulina Łukasik ul. Wierzbowa 64 41-100 Siem...</td>\n",
       "      <td>Joanna Borowska ul. Płońska 48 03-683 Warsza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label_tag label_type                          uwagi  \\\n",
       "0           0          0      dhl_1    Proszę zadzwonić domofonem.   \n",
       "1           0          1   inpost_3  Upewnić się, że ktoś odbierze   \n",
       "2           0          2   inpost_3  Zadzwonić na numer kontaktowy   \n",
       "3           0          3      dhl_1  Proszę o delikatne obchodzeni   \n",
       "4           0          4  pocztex_1  Proszę dostarczyć na tylną fu   \n",
       "\n",
       "                                            odbiorca  \\\n",
       "0    Magdalena Kozak ul. Michałowska 113 03-767 W...   \n",
       "1  MORSKI KWIAT   ul. Wałuszewska 55 03-005 Warsz...   \n",
       "2    Gabriela Pawlik ul. Mickiewicza Adama 113 81...   \n",
       "3    Mariusz Piekarski ul. Mała 144 15-317 Białys...   \n",
       "4    Paulina Łukasik ul. Wierzbowa 64 41-100 Siem...   \n",
       "\n",
       "                                             nadawca  \n",
       "0    Mateusz Stępień ul. Nawigacyjna 19 60-480 Po...  \n",
       "1  SŁONECZNA POLANA   ul. Obrzańska 86 60-114 Poz...  \n",
       "2    Maria Nowak ul. Generała Fiszera Józefa 20 8...  \n",
       "3    Krzysztof Kwiatkowski ul. Brzozowa 125 43-60...  \n",
       "4    Joanna Borowska ul. Płońska 48 03-683 Warsza...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ładowanie zawartości wygenerowanych etykiet z pliku utworzonego podczas generacji\n",
    "# detekcja będzie porównywana do generacji, na tej podstawie zostaną obliczone miary detekcji\n",
    "\n",
    "path_to_train_info_excel = \"data/generated_labels/first_gen_2024-06-24.xlsx\"\n",
    "generated_df = pd.read_excel(path_to_train_info_excel)\n",
    "\n",
    "generated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyliczenia miar\n",
    "\n",
    "W następnych dwóch komórkach obliczane są miary dla wyników detekcji na zbiorze treningowym oraz walidacyjnym (odpowiednio opisane komentarzem). Dodatkowo w trakcie obliczeń zapisywane są przykładowe detekcje w celach pokazowych (obecnie zakomentowana linijka). Finalnie przez odkomentowanie odpowiedniej linijki (opisana komentarzem) da się spojrzeć na pojedyńcze detekcje w porównaniu z targetem (wygenerowanymi danymi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miary dla detekcji zbioru treningowego, z podziałem na typ informacji: \n",
      "\n",
      "Uwagi WER: 0.8982683982683981\n",
      "Nadawca WER: 0.8784149184149185\n",
      "Odbiorca WER: 0.8906549659490834\n",
      "############\n",
      "Uwagi CER: 0.8982683982683981\n",
      "Nadawca CER: 0.8784149184149185\n",
      "Odbiorca CER: 0.8906549659490834\n",
      "############\n",
      "Uwagi MER: 0.6987322201607916\n",
      "Nadawca MER: 0.8572416472416472\n",
      "Odbiorca MER: 0.8215845592316179\n",
      "\n",
      "Miary dla detekcji zbioru treningowego, z podziałem na typ przewoźnika:\n",
      "Inpost WER:  0.8845777979924321\n",
      "Pocztex WER:  0.8731746031746032\n",
      "DPD WER:  0.8663517768780927\n",
      "DHL WER:  0.9228888888888889\n"
     ]
    }
   ],
   "source": [
    "# obliczenia dla zbioru treningowego\n",
    "from pytesseract import Output\n",
    "\n",
    "class_names_dict = {0:\"nadawca\",\n",
    "                    1:\"odbiorca\",\n",
    "                    2:\"uwagi\"}\n",
    "\n",
    "nadawca_scores = []\n",
    "odbiorca_scores = []\n",
    "uwagi_scores = []\n",
    "\n",
    "nadawca_scores_cer = []\n",
    "odbiorca_scores_cer = []\n",
    "uwagi_scores_cer = []\n",
    "\n",
    "nadawca_scores_mer = []\n",
    "odbiorca_scores_mer = []\n",
    "uwagi_scores_mer = []\n",
    "\n",
    "inpost_wer = []\n",
    "dhl_wer = []\n",
    "dpd_wer = []\n",
    "pocztex_wer = []\n",
    "\n",
    "\n",
    "for k, result in enumerate(loaded_train_results):\n",
    "    orig_image = result.orig_img\n",
    "    fullpath = result.path\n",
    "    number = int(fullpath.split(\"_\")[-1][:-5]) # zadziała dla train i val, nie dla test\n",
    "    detected_classes = result.boxes.cls\n",
    "    detected_boxes = result.boxes\n",
    "    \n",
    "    for i, class_detected in enumerate(detected_classes):\n",
    "        class_int = int(class_detected.numpy())\n",
    "        [x1, y1, x2, y2] = detected_boxes[i].xyxy.numpy().astype(int)[0]\n",
    "        fragment = orig_image[y1:y2, x1:x2, :] # działa! \n",
    "        \n",
    "        # #blur\n",
    "        # img = cv2.blur(fragment, (10,10))\n",
    "        \n",
    "        # #sharpen\n",
    "        # kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        # img = cv2.filter2D(img, -1, kernel)\n",
    "        \n",
    "        img = get_grayscale(fragment)\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        # img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "        #     cv2.THRESH_BINARY,11,2)\n",
    "        img = thresholding(img)\n",
    "        \n",
    "        #open\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        #close\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        \n",
    "        text_on_fragment = pytesseract.image_to_string(img)\n",
    "\n",
    "        text_category = class_names_dict[class_int]\n",
    "        text_to_decipher = generated_df.iloc[number][text_category]\n",
    "        label_type = generated_df.iloc[number]['label_type'].split('_')[0]\n",
    "        \n",
    "        wer = jiwer.wer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "\n",
    "        cer = jiwer.cer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "        \n",
    "        mer = jiwer.mer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        if label_type == \"inpost\":\n",
    "            inpost_wer.append(wer)\n",
    "        elif label_type == \"dhl\":\n",
    "            dhl_wer.append(wer)\n",
    "        elif label_type == \"pocztex\":\n",
    "            pocztex_wer.append(wer)\n",
    "        else:\n",
    "            dpd_wer.append(wer)\n",
    "        \n",
    "        if class_int == 0:\n",
    "            nadawca_scores.append(wer)\n",
    "            nadawca_scores_cer.append(cer)\n",
    "            nadawca_scores_mer.append(mer)\n",
    "        elif class_int == 1:\n",
    "            odbiorca_scores.append(wer)\n",
    "            odbiorca_scores_cer.append(cer)\n",
    "            odbiorca_scores_mer.append(mer)\n",
    "        elif class_int == 2:\n",
    "            uwagi_scores.append(wer)\n",
    "            uwagi_scores_cer.append(cer)\n",
    "            uwagi_scores_mer.append(mer)\n",
    "        \n",
    "        # cały fragment w dół jedynie dla wglądu w wyniki w razie potrzeby\n",
    "        if k in [4, 15, 17]:\n",
    "            \n",
    "            # dla wglądu w to co model wykrywa (tekst) i porównania co powinno wykryć, odkomentować ponizsza linijke\n",
    "            #####\n",
    "            # print(\"Co wykryło: \\n ######### \\n\", text_on_fragment, \"\\n #########, co miało być: ######### \\n\", text_to_decipher, \"\\n\\n\")\n",
    "            #####\n",
    "            \n",
    "            # umieszczanie bounding boxów na obrazach\n",
    "            d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "            n_boxes = len(d['level'])\n",
    "            for j in range(n_boxes):\n",
    "                (x, y, w, h) = (d['left'][j], d['top'][j], d['width'][j], d['height'][j])\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.rectangle(fragment, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # dla zapisu przykładowych detekcji odkomentowac ponizsze dwie linijki\n",
    "            #####\n",
    "            # cv2.imwrite(f\"tess_view_i{i}_k{k}.png\", img)\n",
    "            # cv2.imwrite(f\"wycinek_i{i}_k{k}.png\", fragment)\n",
    "            ####\n",
    "            \n",
    "            \n",
    "print(\"Miary dla detekcji zbioru treningowego, z podziałem na typ informacji: \\n\")\n",
    "print(\"Uwagi WER:\", np.mean(uwagi_scores))\n",
    "print(\"Nadawca WER:\", np.mean(nadawca_scores))\n",
    "print(\"Odbiorca WER:\", np.mean(odbiorca_scores))\n",
    "print(\"############\")\n",
    "print(\"Uwagi CER:\", np.mean(uwagi_scores_cer))\n",
    "print(\"Nadawca CER:\", np.mean(nadawca_scores_cer))\n",
    "print(\"Odbiorca CER:\", np.mean(odbiorca_scores_cer))\n",
    "print(\"############\")\n",
    "print(\"Uwagi MER:\", np.mean(uwagi_scores_mer))\n",
    "print(\"Nadawca MER:\", np.mean(nadawca_scores_mer))\n",
    "print(\"Odbiorca MER:\", np.mean(odbiorca_scores_mer))\n",
    "print(\"\\nMiary dla detekcji zbioru treningowego, z podziałem na typ przewoźnika:\")\n",
    "print(\"Inpost WER: \", np.mean(inpost_wer))\n",
    "print(\"Pocztex WER: \", np.mean(pocztex_wer))\n",
    "print(\"DPD WER: \", np.mean(dpd_wer))\n",
    "print(\"DHL WER: \", np.mean(dhl_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miary dla detekcji zbioru WALIDACYJNEGO, z podziałem na typ informacji: \n",
      "\n",
      "Uwagi WER: 0.8973684210526316\n",
      "Nadawca WER: 0.8730158730158731\n",
      "Odbiorca WER: 0.9765647051361338\n",
      "############\n",
      "Uwagi CER: 0.8973684210526316\n",
      "Nadawca CER: 0.8730158730158731\n",
      "Odbiorca CER: 0.9765647051361338\n",
      "############\n",
      "Uwagi MER: 0.7472431077694235\n",
      "Nadawca MER: 0.8239435168006598\n",
      "Odbiorca MER: 0.7944896528930142\n",
      "\n",
      "Miary dla detekcji zbioru WALIDACYJNEGO, z podziałem na typ przewoźnika:\n",
      "Inpost WER:  0.8953848833159178\n",
      "Pocztex WER:  0.8753086419753087\n",
      "DPD WER:  1.2559567416710276\n",
      "DHL WER:  0.7938271604938271\n"
     ]
    }
   ],
   "source": [
    "# teraz obliczenia dla zbioru walidacyjnego\n",
    "\n",
    "class_names_dict = {0:\"nadawca\",\n",
    "                    1:\"odbiorca\",\n",
    "                    2:\"uwagi\"}\n",
    "\n",
    "nadawca_scores = []\n",
    "odbiorca_scores = []\n",
    "uwagi_scores = []\n",
    "\n",
    "nadawca_scores_cer = []\n",
    "odbiorca_scores_cer = []\n",
    "uwagi_scores_cer = []\n",
    "\n",
    "nadawca_scores_mer = []\n",
    "odbiorca_scores_mer = []\n",
    "uwagi_scores_mer = []\n",
    "\n",
    "inpost_wer = []\n",
    "dhl_wer = []\n",
    "dpd_wer = []\n",
    "pocztex_wer = []\n",
    "\n",
    "\n",
    "for k, result in enumerate(loaded_val_results):\n",
    "    orig_image = result.orig_img\n",
    "    fullpath = result.path\n",
    "    number = int(fullpath.split(\"_\")[-1][:-5]) # zadziała dla train i val, nie dla test\n",
    "    detected_classes = result.boxes.cls\n",
    "    detected_boxes = result.boxes\n",
    "    \n",
    "    for i, class_detected in enumerate(detected_classes):\n",
    "        class_int = int(class_detected.numpy())\n",
    "        [x1, y1, x2, y2] = detected_boxes[i].xyxy.numpy().astype(int)[0]\n",
    "        fragment = orig_image[y1:y2, x1:x2, :] # działa! \n",
    "        \n",
    "        \n",
    "        img = get_grayscale(fragment)\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "        img = thresholding(img)\n",
    "        \n",
    "        #open\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        #close\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "\n",
    "        text_on_fragment = pytesseract.image_to_string(img)\n",
    "\n",
    "        text_category = class_names_dict[class_int]\n",
    "        text_to_decipher = generated_df.iloc[number][text_category]\n",
    "        label_type = generated_df.iloc[number]['label_type'].split('_')[0]\n",
    "        \n",
    "        wer = jiwer.wer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "\n",
    "        cer = jiwer.cer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "        \n",
    "        mer = jiwer.mer(\n",
    "                text_to_decipher,\n",
    "                text_on_fragment,\n",
    "                truth_transform=transforms,\n",
    "                hypothesis_transform=transforms,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        if label_type == \"inpost\":\n",
    "            inpost_wer.append(wer)\n",
    "        elif label_type == \"dhl\":\n",
    "            dhl_wer.append(wer)\n",
    "        elif label_type == \"pocztex\":\n",
    "            pocztex_wer.append(wer)\n",
    "        else:\n",
    "            dpd_wer.append(wer)\n",
    "        \n",
    "        if class_int == 0:\n",
    "            nadawca_scores.append(wer)\n",
    "            nadawca_scores_cer.append(cer)\n",
    "            nadawca_scores_mer.append(mer)\n",
    "        elif class_int == 1:\n",
    "            odbiorca_scores.append(wer)\n",
    "            odbiorca_scores_cer.append(cer)\n",
    "            odbiorca_scores_mer.append(mer)\n",
    "        elif class_int == 2:\n",
    "            uwagi_scores.append(wer)\n",
    "            uwagi_scores_cer.append(cer)\n",
    "            uwagi_scores_mer.append(mer)\n",
    "            \n",
    "        # cały fragment w dół jedynie dla wglądu w wyniki w razie potrzeby\n",
    "        if k in [4, 15, 17]:\n",
    "            \n",
    "            # dla wglądu w to co model wykrywa (tekst) i porównania co powinno wykryć, odkomentować ponizsza linijke\n",
    "            #####\n",
    "            # print(\"Co wykryło: \\n ######### \\n\", text_on_fragment, \"\\n #########, co miało być: ######### \\n\", text_to_decipher, \"\\n\\n\")\n",
    "            #####\n",
    "            \n",
    "            # umieszczanie bounding boxów na obrazach\n",
    "            d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "            n_boxes = len(d['level'])\n",
    "            for j in range(n_boxes):\n",
    "                (x, y, w, h) = (d['left'][j], d['top'][j], d['width'][j], d['height'][j])\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.rectangle(fragment, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # dla zapisu przykładowych detekcji odkomentowac ponizsze dwie linijki\n",
    "            #####\n",
    "            # cv2.imwrite(f\"tess_view_i{i}_k{k}.png\", img)\n",
    "            # cv2.imwrite(f\"wycinek_i{i}_k{k}.png\", fragment)\n",
    "            ####\n",
    "     \n",
    "            \n",
    "print(\"Miary dla detekcji zbioru WALIDACYJNEGO, z podziałem na typ informacji: \\n\")\n",
    "print(\"Uwagi WER:\", np.mean(uwagi_scores))\n",
    "print(\"Nadawca WER:\", np.mean(nadawca_scores))\n",
    "print(\"Odbiorca WER:\", np.mean(odbiorca_scores))\n",
    "print(\"############\")\n",
    "print(\"Uwagi CER:\", np.mean(uwagi_scores_cer))\n",
    "print(\"Nadawca CER:\", np.mean(nadawca_scores_cer))\n",
    "print(\"Odbiorca CER:\", np.mean(odbiorca_scores_cer))\n",
    "print(\"############\")\n",
    "print(\"Uwagi MER:\", np.mean(uwagi_scores_mer))\n",
    "print(\"Nadawca MER:\", np.mean(nadawca_scores_mer))\n",
    "print(\"Odbiorca MER:\", np.mean(odbiorca_scores_mer))\n",
    "print(\"\\nMiary dla detekcji zbioru WALIDACYJNEGO, z podziałem na typ przewoźnika:\")\n",
    "print(\"Inpost WER: \", np.mean(inpost_wer))\n",
    "print(\"Pocztex WER: \", np.mean(pocztex_wer))\n",
    "print(\"DPD WER: \", np.mean(dpd_wer))\n",
    "print(\"DHL WER: \", np.mean(dhl_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
